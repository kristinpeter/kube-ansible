---
# Join Worker Nodes to Kubernetes Cluster
# This playbook joins worker nodes to the initialized cluster

- name: "*** Join Worker Nodes"
  hosts: k8s_workers
  become: yes
  gather_facts: yes
  serial: "{{ ansible_serial | default(2) }}"  # Join workers in small batches
  vars_files:
    - "{{ playbook_dir }}/../../group_vars/all.yml"
  
  pre_tasks:
    - name: "Download: Retrieve worker join command from primary master"
      slurp:
        src: /tmp/worker_join_command
      register: worker_join_file
      delegate_to: "{{ groups['k8s_masters'][0] }}"
      become: yes
      when: worker_join_command is undefined or worker_join_command == ""
      
    - name: "Set: Set worker join command from file"
      set_fact:
        worker_join_command: "{{ worker_join_file.content | b64decode | trim }}"
      when: worker_join_file is defined and worker_join_file.content is defined
      
    - name: "Safety: Verify join command is available"
      fail:
        msg: |
          ==========================================
          ERROR: WORKER JOIN COMMAND NOT FOUND
          ==========================================
          
          The worker join command was not generated by the primary master.
          
          This usually means:
          1. Primary master initialization failed
          2. Token generation failed
          3. Network connectivity issues
          
          Check the primary master initialization logs.
      when: worker_join_command is undefined or worker_join_command == ""
      
    - name: "Check: Check if this worker is already joined"
      stat:
        path: /etc/kubernetes/kubelet.conf
      register: kubelet_conf_check
      
    - name: "INFO: Worker already joined - skipping"
      debug:
        msg: "Worker {{ inventory_hostname }} is already part of the cluster"
      when: kubelet_conf_check.stat.exists
      
    - name: "Check: Skip already joined workers"
      meta: end_host
      when: kubelet_conf_check.stat.exists

  tasks:
    - name: "*** Join worker to cluster"
      shell: "{{ worker_join_command }}"
      register: worker_join_result
      timeout: 300
      retries: 3
      until: worker_join_result is succeeded
      
    - name: "Display: Display join output"
      debug:
        var: worker_join_result.stdout_lines
        
    - name: "Wait: Wait for kubelet to start"
      systemd:
        name: kubelet
        state: started
      register: kubelet_start
      retries: 5
      delay: 10
      until: kubelet_start is succeeded
      
    - name: "Wait: Wait for node to join cluster"
      shell: kubectl --kubeconfig=/etc/kubernetes/admin.conf get nodes {{ inventory_hostname_short }} --no-headers
      delegate_to: "{{ groups['k8s_masters'][0] }}"
      register: node_status
      become: yes
      retries: 12
      delay: 10
      until: node_status is succeeded
      vars:
        inventory_hostname_short: "{{ inventory_hostname.split('.')[0] }}"
      
    - name: "Verify: Verify worker node joined successfully"
      shell: kubectl --kubeconfig=/etc/kubernetes/admin.conf get nodes {{ inventory_hostname_short }} -o wide
      delegate_to: "{{ groups['k8s_masters'][0] }}"
      register: worker_node_info
      become: yes
      vars:
        inventory_hostname_short: "{{ inventory_hostname.split('.')[0] }}"
      
    - name: "Summary: Worker join summary"
      debug:
        msg:
          - "=== WORKER JOINED SUCCESSFULLY ==="
          - "Node: {{ inventory_hostname }}"
          - "Status: {{ worker_node_info.stdout_lines }}"
          - ""
          - "Verify: Worker is ready for workloads"

  post_tasks:
    - name: "Summary: All workers join summary"
      debug:
        msg:
          - "=== ALL WORKERS JOINED ==="
          - "Total Workers: {{ groups['k8s_workers'] | length }}"
          - "Cluster Size: {{ groups['k8s_cluster'] | length }} nodes"
          - "  - Masters: {{ groups['k8s_masters'] | length }}"
          - "  - Workers: {{ groups['k8s_workers'] | length }}"
          - ""
          - "Verify: All nodes joined - ready for CNI installation"
      run_once: true